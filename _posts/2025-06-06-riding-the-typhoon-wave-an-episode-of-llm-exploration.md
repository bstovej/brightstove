---
layout: post
title: "Riding the Typhoon wave: An episode of LLM exploration"
date: 2025-06-06 13:24:33
categories: [AI Risk, AI Security, AI Governance]
tags: [AI risk, cybersecurity]
---

<!-- wp:paragraph -->
<p>Was exploring a few open source LLMs installed in my laptop and observed some strange behaviors. Maybe someone here can help to explain why. More importantly, the episode reinforced the following to keep in mind when using LLM chatbots:&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>1. Craft the prompt carefully upfront. Be as specific as possible. Avoid using general terms, which will get general responses.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>2. After getting the response, turn off the web search if what you need the LLM to do next is to work on those responses instead of finding new input.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>3. Start a new chat window when moving to a new context to avoid confusing the LLM.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>4. For better results, use specialized/fine-tuned LLM for tasks that are in a specialized domain.&nbsp;</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>5. If you have RAG setup, use it to analyze instead of just using the web search feature, which should produce better results.</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p>Check it out at: https://substack.com/profile/324848066-meng-chow-kang/note/c-123368408?utm_source=substack&amp;utm_content=first-note-modal</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p></p>
<!-- /wp:paragraph -->